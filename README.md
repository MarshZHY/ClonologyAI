# Clonology.AI

<div align="center">

![ClonologyAI Logo](https://img.shields.io/badge/ClonologyAI-Advanced%20Memory%20Cloning-blue?style=for-the-badge)

**Transform Your Chat History into Intelligent AI Clones**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3.3-green.svg)](https://flask.palletsprojects.com/)
[![LangChain](https://img.shields.io/badge/LangChain-0.0.267-orange.svg)](https://python.langchain.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

[ğŸš€ Quick Start](#quick-start) â€¢ [ğŸ“– Documentation](#documentation) â€¢ [ğŸ¯ Features](#features) â€¢ [ğŸ› ï¸ Installation](#installation) â€¢ [ğŸ¤ Contributing](#contributing)

</div>

---

## ğŸŒŸ Overview

ClonologyAI is an advanced AI platform that creates personalized AI models from your chat history. Using state-of-the-art memory cloning technology, it learns your unique communication style, personality traits, and conversational patterns to create an AI clone that speaks just like you.

### âœ¨ Key Highlights

- ğŸ§  **Memory-Aware Conversations** - Your AI clone remembers past interactions and context
- ğŸ­ **Personality Cloning** - Captures your unique communication style and mannerisms  
- ğŸ“Š **Human Evaluation** - Compare AI clone performance against baseline models
- ğŸ”§ **Customizable Processing** - Adjustable memory precision and processing speed

---

## ğŸ¯ Features

### ğŸ—ï¸ **AI Clone Creation**
- Upload your chat history (JSON format)
- Select participant to clone
- Configurable memory processing (Precise/Balanced/Fast modes)
- Automatic participant detection and analysis

### ğŸ’¬ **Direct Chat Interface**
- Natural conversation with your AI clone
- Real-time response generation
- Memory-aware context understanding
- Personalized communication style matching

### ğŸ“ˆ **Performance Evaluation**
- Human evaluation system with A/B testing
- Compare AI clone vs baseline models
- Multiple evaluation types:
  - ğŸ’¬ Natural Chat
  - ğŸ§  Memory Recall  
  - ğŸ‘¤ Personalization
  - â¤ï¸ Emotional Support
- Real-time analytics and performance metrics

### ğŸ” **Advanced Analytics**
- Comprehensive chat analysis and statistics
- Message distribution and pattern recognition
- Emoji usage and communication style analysis
- Question pattern identification

---

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8 or higher
- OpenAI API key (or compatible LLM API)
- 4GB+ RAM recommended for processing

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ClonologyAI.git
cd ClonologyAI
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Environment Setup

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key_here
TYPHOON_API_KEY=your_typhoon_api_key_here  # Optional: for Thai language support
```

Or update the [`config.json`](config.json) file:

```json
{
  "api_key": "your_api_key_here"
}
```

### 4. Initialize Model Structure

```bash
python app.py
```

The application will automatically create the necessary model directories and files.

---

## ğŸš€ Quick Start

### 1. Start the Application

```bash
python app.py
```

Visit `http://localhost:5000` to access the web interface.

### 2. Create Your AI Clone

1. **Upload Data**: Go to [`/setup`](http://localhost:5000/setup) and upload your chat history JSON file
2. **Select Participant**: Choose which participant from your chat to clone
3. **Configure Processing**: Adjust memory processing settings (1-10 scale)
4. **Process**: Wait for the AI clone creation to complete

### 3. Start Chatting

1. **Direct Chat**: Visit [`/direct_chat`](http://localhost:5000/direct_chat) to chat with your AI clone
2. **Evaluation**: Use [`/index`](http://localhost:5000/index) to compare your AI clone against baseline models

---

## ğŸ“Š Project Structure

```
ClonologyAI/
â”œâ”€â”€ ğŸ“ static/                 # Frontend assets
â”‚   â”œâ”€â”€ styles.css            # Modern UI styling
â”‚   â”œâ”€â”€ script.js             # Main JavaScript functionality
â”‚   â””â”€â”€ script.js.new         # Updated JavaScript features
â”œâ”€â”€ ğŸ“ templates/             # HTML templates
â”‚   â”œâ”€â”€ home.html             # Landing page
â”‚   â”œâ”€â”€ setup.html            # AI clone creation
â”‚   â”œâ”€â”€ direct_chat.html      # Chat interface
â”‚   â””â”€â”€ index.html            # Evaluation interface
â”œâ”€â”€ ğŸ“ model/                 # AI model storage
â”‚   â””â”€â”€ default/              # Default model directory
â”œâ”€â”€ app.py                    # Main Flask application
â”œâ”€â”€ modeling.py               # AI model processing
â”œâ”€â”€ chat_rag.py              # RAG implementation
â”œâ”€â”€ chat_eda.py              # Chat analysis
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ config.json              # Configuration
â””â”€â”€ README.md                # This file
```

---

## ğŸ”§ Configuration

### Memory Processing Settings

The [`modeling.py`](modeling.py) module supports various configuration options:

- **Chunk Size**: Adjustable message chunking (1000-5000 tokens)
- **Processing Modes**: 
  - Precise (1-3): Detailed analysis, slower processing
  - Balanced (4-7): Optimal speed/accuracy balance  
  - Fast (8-10): Quick processing, larger chunks

### LLM Configuration

Update the [`initialize_llm()`](modeling.py) function to use different language models:

```python
def initialize_llm():
    return ChatOpenAI(
        model_name="gpt-4",  # or your preferred model
        temperature=0.7,
        max_tokens=2000
    )
```

---

## ğŸ” API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/models` | GET | Get available AI models |
| `/api/chat` | POST | Chat with AI clone |
| `/api/evaluate` | POST | Evaluate AI responses |
| `/api/process_model` | POST | Start model processing |
| `/api/process_status` | GET | Get processing status |

---

## ğŸ§ª Testing

### Chat Analysis

Run comprehensive chat analysis:

```bash
python chat_eda.py
```

This generates detailed analytics in the `analysis_results/` directory.

### Model Evaluation

The evaluation system provides multiple testing scenarios:

1. **Natural Chat**: Test conversational abilities
2. **Memory Recall**: Evaluate memory and context understanding  
3. **Personalization**: Assess personality matching
4. **Emotional Support**: Test empathy and emotional responses

---

## ğŸ“š Dependencies

Key dependencies from [`requirements.txt`](requirements.txt):

```txt
flask==2.3.3
langchain==0.0.267
openai==0.27.8
python-dotenv==1.0.0
pandas>=1.3.0
numpy>=1.20.0
scikit-learn>=0.24.0
```

For Thai language support:
```txt
pythainlp>=3.0.0
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Guidelines

- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation as needed
- Ensure backward compatibility

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LangChain** for the powerful LLM framework
- **Hugging Face** for embedding models
- **FAISS** for efficient similarity search
- **Flask** for the web framework

---

## ğŸ“ Support

- ğŸ› **Bug Reports**: [Open an issue](https://github.com/yourusername/ClonologyAI/issues)
- ğŸ’¡ **Feature Requests**: [Start a discussion](https://github.com/yourusername/ClonologyAI/discussions)
- ğŸ“§ **Contact**: your.email@example.com

---

<div align="center">

**â­ Star this repository if you find it helpful!**

Made with â¤ï¸ by the ClonologyAI Team

</div>
